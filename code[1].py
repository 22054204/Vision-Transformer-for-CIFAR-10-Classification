# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LMMIlxTGce9BBYo4Zr8twANg-m8UmytV
"""

# ====================== Assignment 4 â€“ Vision Transformer (Roll: 22054204) ======================
# Name : Ranjan Sharma | Section : CSE 24
# Model Name : CIFARViT_404  (6 layers, StepLR, ReLU MLP, custom naming)

# If running in a fresh Colab environment uncomment the next line
# !pip install torch torchvision scikit-learn matplotlib -q

# ---- Imports ----
import torch, torch.nn as nn, torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np, random, os, math, shutil

# ---- Device ----
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ðŸ‘¾ Device active: {DEVICE}")

# ---- Roll Based Config ----
ROLL_ID = 22054204
np.random.seed(ROLL_ID); random.seed(ROLL_ID); torch.manual_seed(ROLL_ID)
if DEVICE == "cuda":
    torch.cuda.manual_seed_all(ROLL_ID)

# derive raw values from roll
HID_raw = 112 + (ROLL_ID % 8) * 16    # raw hidden dim (may be adjusted to be divisible by heads)
N_HEAD = 3 + (ROLL_ID % 5)            # heads from roll
PATCH_SZ = 10 + (ROLL_ID % 3) * 2
EPOCH_RUN = 11 + (ROLL_ID % 4)
LRATE = 5e-4
BATCH_SZ = 128
IMG_DIM, CLASS_NO = 32, 10

# ensure HID is divisible by heads by rounding HID up to nearest multiple of N_HEAD
if HID_raw % N_HEAD != 0:
    HID = HID_raw + ((N_HEAD - (HID_raw % N_HEAD)) % N_HEAD)
    print(f"[WARN] HID_raw={HID_raw} not divisible by heads={N_HEAD} -> adjusting HID to {HID}")
else:
    HID = HID_raw

print(f"[CONFIG] dim={HID}  heads={N_HEAD}  patch={PATCH_SZ}  epochs={EPOCH_RUN}")

# ---- Pad helper ----
def pad_img_to_patch(x, p):
    h, w = x.shape[-2:]
    H = (h + p - 1) // p * p
    W = (w + p - 1) // p * p
    return F.pad(x, (0, W - w, 0, H - h))

# ---- Patch embedding ----
class Patchify(nn.Module):
    def __init__(self, p=PATCH_SZ, ch=3, dim=HID):
        super().__init__()
        self.p = p
        self.map = nn.Conv2d(ch, dim, kernel_size=p, stride=p)
    def forward(self, x):
        x = pad_img_to_patch(x, self.p)
        x = self.map(x)                      # B x dim x H_p x W_p
        return x.flatten(2).transpose(1, 2)  # B x N_patches x dim

# ---- Multi-head attention ----
class AttBlock(nn.Module):
    def __init__(self, dim=HID, heads=N_HEAD):
        super().__init__()
        assert dim % heads == 0, f"dim ({dim}) must be divisible by heads ({heads})"
        self.h, self.d = heads, dim // heads
        self.to_qkv = nn.Linear(dim, dim * 3)
        self.out = nn.Linear(dim, dim)
        self.snapshot = None
    def forward(self, x):
        B, N, C = x.shape
        q, k, v = self.to_qkv(x).chunk(3, dim=-1)
        q = q.view(B, N, self.h, self.d).transpose(1, 2)
        k = k.view(B, N, self.h, self.d).transpose(1, 2)
        v = v.view(B, N, self.h, self.d).transpose(1, 2)
        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.d)
        att = att.softmax(dim=-1)
        try:
            # store a detached CPU copy for later visualization
            self.snapshot = att.detach().cpu()
        except Exception:
            self.snapshot = None
        x = (att @ v).transpose(1, 2).reshape(B, N, C)
        return self.out(x)

# ---- Transformer Block ----
class EncoderLayer(nn.Module):
    def __init__(self, dim=HID, heads=N_HEAD):
        super().__init__()
        self.norm1, self.norm2 = nn.LayerNorm(dim), nn.LayerNorm(dim)
        self.att = AttBlock(dim, heads)
        self.ff = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.ReLU(),
            nn.Linear(dim * 4, dim)
        )
    def forward(self, x):
        x = x + self.att(self.norm1(x))
        x = x + self.ff(self.norm2(x))
        return x

# ---- Full ViT ----
class CIFARViT_404(nn.Module):
    def __init__(self):
        super().__init__()
        self.patcher = Patchify()
        self.cls_vec = nn.Parameter(torch.zeros(1, 1, HID))
        self.pos_vec = nn.Parameter(torch.randn(1, 400, HID) * 0.02)
        self.layers = nn.ModuleList([EncoderLayer() for _ in range(6)])   # 6 layers
        self.out_norm = nn.LayerNorm(HID)
        self.classifier = nn.Linear(HID, CLASS_NO)
    def forward(self, x):
        x = self.patcher(x)
        B, N, _ = x.shape
        cls = self.cls_vec.expand(B, -1, -1)
        x = torch.cat([cls, x], dim=1)
        x = x + self.pos_vec[:, :N + 1]
        for blk in self.layers:
            x = blk(x)
        return self.classifier(self.out_norm(x[:, 0]))
    def extract_att(self):
        for b in reversed(self.layers):
            if hasattr(b, "att") and getattr(b.att, "snapshot", None) is not None:
                return b.att.snapshot
        return None

# ---- Dataset ----
tf = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),
])
trainset = datasets.CIFAR10("/content/data", train=True, download=True, transform=tf)
testset  = datasets.CIFAR10("/content/data", train=False, download=True, transform=tf)
vlen = int(len(trainset) * 0.1)
trainset, valset = random_split(trainset, [len(trainset) - vlen, vlen])

train_loader = DataLoader(trainset, batch_size=BATCH_SZ, shuffle=True,
                          num_workers=2, pin_memory=True if DEVICE=="cuda" else False)
val_loader   = DataLoader(valset, batch_size=BATCH_SZ, num_workers=2, pin_memory=True if DEVICE=="cuda" else False)
test_loader  = DataLoader(testset, batch_size=BATCH_SZ, num_workers=2, pin_memory=True if DEVICE=="cuda" else False)

# ---- Setup ----
net = CIFARViT_404().to(DEVICE)
opt = torch.optim.Adam(net.parameters(), lr=LRATE)
scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=5, gamma=0.7)
criterion = nn.CrossEntropyLoss()

os.makedirs("/content/vit_404", exist_ok=True)

# ---- Eval Function ----
def evaluate(loader):
    net.eval(); correct, total, yt, yp = 0, 0, [], []
    with torch.no_grad():
        for img, lbl in loader:
            img, lbl = img.to(DEVICE), lbl.to(DEVICE)
            preds = net(img).argmax(1)
            correct += (preds == lbl).sum().item()
            total += lbl.size(0)
            yt += lbl.cpu().tolist()
            yp += preds.cpu().tolist()
    return (correct / total) if total>0 else 0.0, np.array(yt), np.array(yp)

# ---- Training ----
t_hist, v_hist = [], []
for ep in range(1, EPOCH_RUN + 1):
    net.train(); c, t = 0, 0
    for img, lbl in train_loader:
        img, lbl = img.to(DEVICE), lbl.to(DEVICE)
        opt.zero_grad()
        out = net(img)
        loss = criterion(out, lbl)
        loss.backward(); opt.step()
        c += (out.argmax(1) == lbl).sum().item()
        t += lbl.size(0)
    accuracy = c / t if t > 0 else 0.0
    val_accuracy, _, _ = evaluate(val_loader)
    scheduler.step()
    t_hist.append(accuracy); v_hist.append(val_accuracy)
    print(f"[EPOCH {ep}/{EPOCH_RUN}] train={accuracy:.3f} | val={val_accuracy:.3f}")
    torch.save(net.state_dict(), "/content/vit_404/model_404.pth")

# ---- Plot curve ----
plt.figure()
plt.plot(t_hist, label="Train")
plt.plot(v_hist, label="Val")
plt.title("Accuracy Graph â€“ Roll 22054204")
plt.legend()
plt.savefig("/content/vit_404/curve_404.png")
plt.close()

# ---- Test & Confusion ----
tst_acc, y_t, y_p = evaluate(test_loader)
print(f"\nâœ… TEST ACCURACY: {round(tst_acc,4)}")
cm = confusion_matrix(y_t, y_p)
disp = ConfusionMatrixDisplay(cm)
disp.plot(values_format='d', cmap="Greens")
plt.title("Confusion Matrix â€“ 404")
plt.savefig("/content/vit_404/cm_404.png")
plt.close()

# ---- Attention Visual (min-max normalized) ----
att = net.extract_att()
if att is not None:
    # att shape: (B, heads, N, N) or (heads, N, N)
    att_arr = att.mean(0).mean(0) if isinstance(att, torch.Tensor) else np.array(att).mean(0).mean(0)
    if isinstance(att_arr, torch.Tensor):
        att_arr = att_arr.cpu().numpy()
    att_norm = (att_arr - att_arr.min()) / (att_arr.max() - att_arr.min() + 1e-6)
    plt.imshow(att_norm, cmap="coolwarm")
    plt.title("Attention Map â€“ 404")
    plt.colorbar()
    plt.savefig("/content/vit_404/att_404.png")
    plt.close()
else:
    print("âš  No attention stored.")

# ---- Zip & Download ----
shutil.make_archive("/content/vit_404", "zip", "/content/vit_404")

try:
    from google.colab import files
    files.download("/content/vit_404.zip")
except Exception:
    print("Saved archive to /content/vit_404.zip â€” download it from the runtime file browser or copy to drive if needed.")

print("\nðŸŽ‰ DONE! All output stored in /content/vit_404 (and vit_404.zip)")